{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc20a464-143d-4ded-9135-25e13f86c97f",
   "metadata": {},
   "source": [
    "# Liner demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4f33f-f4ed-41e9-9286-829078529efe",
   "metadata": {},
   "source": [
    "## One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c5146e-a2d8-4d06-818b-668e348ff00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params (bias, weight): -0.8141747117042542 42.61933898925781\n",
      "final MSE: 114.1714859008789\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_np, y_np = make_regression(n_samples=100, n_features=1, noise=10.0, random_state=0)\n",
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# 线性模型 y = b + w*x\n",
    "w = torch.zeros((1,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "opt = torch.optim.SGD([w, b], lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "\tpreds = X.mm(w) + b        # 前向\n",
    "\tloss = loss_fn(preds, y)\n",
    "\topt.zero_grad()\n",
    "\tloss.backward()             # 自动计算梯度\n",
    "\topt.step()                  # 参数更新由优化器完成\n",
    "\n",
    "print(\"params (bias, weight):\", b.item(), w.item())\n",
    "print(\"final MSE:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4ac48-0b7c-4d9f-b4be-f0577a335c38",
   "metadata": {},
   "source": [
    "## Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73519456-4e39-482b-8d1e-f3cc5c5deaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4d8f67-0784-473b-9465-f1c65f6f0349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.35955316]\n",
      " [ 0.97663904]\n",
      " [ 0.40234164]\n",
      " [-0.81314628]\n",
      " [-0.88778575]\n",
      " [ 0.44386323]\n",
      " [-0.97727788]\n",
      " [ 0.42833187]\n",
      " [ 0.20827498]\n",
      " [-0.31155253]]\n",
      "[-19.95588561  21.33977271  11.55689458 -16.34206917 -35.70063849\n",
      "  27.99539547 -56.32353045  17.61041414  21.45106196 -22.35286466]\n",
      "tensor([[-0.3596],\n",
      "        [ 0.9766],\n",
      "        [ 0.4023],\n",
      "        [-0.8131],\n",
      "        [-0.8878],\n",
      "        [ 0.4439],\n",
      "        [-0.9773],\n",
      "        [ 0.4283],\n",
      "        [ 0.2083],\n",
      "        [-0.3116]])\n",
      "tensor([[-19.9559],\n",
      "        [ 21.3398],\n",
      "        [ 11.5569],\n",
      "        [-16.3421],\n",
      "        [-35.7006],\n",
      "        [ 27.9954],\n",
      "        [-56.3235],\n",
      "        [ 17.6104],\n",
      "        [ 21.4511],\n",
      "        [-22.3529]])\n"
     ]
    }
   ],
   "source": [
    "X_np, y_np = make_regression(n_samples=100, n_features=1, noise=10.0, random_state=0)\n",
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(X_np[:10])\n",
    "print(y_np[:10])\n",
    "print(X[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8feae84e-ff37-4645-b6ff-bbab1ce51ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 线性模型 y = b + w*x\n",
    "w = torch.zeros((1,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "opt = torch.optim.SGD([w, b], lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3504d912-534c-4a00-8f5c-fd0d289cb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = lambda epoch,step,w,b,loss: {\"epoch\": epoch, \"step\": step, \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()}\n",
    "recouter = lambda print_fn,epoch,step,w,b,loss,rti=-1: [\n",
    "\tr := recorder(epoch,step,w,b,loss), \n",
    "\tx := type('',(),r)(), \n",
    "\tprint_fn(f\"({x.epoch}) {x.step} - w: {x.w}, w.grad: {getattr(x,'w.grad')}; b: {x.b}, b.grad: {getattr(x,'b.grad')}; loss: {x.loss}\"), \n",
    "\tx][rti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f922e029-5f38-4164-a237-e76f27a67fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) a - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) b - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) c - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) d - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) e - w: 0.0, w.grad: tensor([[-86.7954]]); b: 0.0, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(0) f - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) a - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) b - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) c - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1887.6624755859375\n",
      "(1) d - w: 0.8679539561271667, w.grad: None; b: 0.03469603508710861, b.grad: None; loss: 1887.6624755859375\n",
      "(1) e - w: 0.8679539561271667, w.grad: tensor([[-85.0217]]); b: 0.03469603508710861, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(1) f - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) a - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) b - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) c - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1816.00830078125\n",
      "(2) d - w: 1.7181705236434937, w.grad: None; b: 0.06765993684530258, b.grad: None; loss: 1816.00830078125\n",
      "(2) e - w: 1.7181705236434937, w.grad: tensor([[-83.2843]]); b: 0.06765993684530258, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(2) f - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(3) a - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(3) b - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(3) c - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1747.2589111328125\n",
      "(3) d - w: 2.551013469696045, w.grad: None; b: 0.09894756227731705, b.grad: None; loss: 1747.2589111328125\n",
      "(3) e - w: 2.551013469696045, w.grad: tensor([[-81.5825]]); b: 0.09894756227731705, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(3) f - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(4) a - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(4) b - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(4) c - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1681.2962646484375\n",
      "(4) d - w: 3.3668389320373535, w.grad: None; b: 0.12861321866512299, b.grad: None; loss: 1681.2962646484375\n",
      "(4) e - w: 3.3668389320373535, w.grad: tensor([[-79.9157]]); b: 0.12861321866512299, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(4) f - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(5) a - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(5) b - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(5) c - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1618.006591796875\n",
      "(5) d - w: 4.165996074676514, w.grad: None; b: 0.1567097008228302, b.grad: None; loss: 1618.006591796875\n",
      "(5) e - w: 4.165996074676514, w.grad: tensor([[-78.2830]]); b: 0.1567097008228302, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "(5) f - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "params (bias, weight): 0.1832883358001709 4.948826313018799\n",
      "final MSE: 1618.006591796875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# records, loss, preds = [], torch.tensor(float('nan')), None\n",
    "# for epoch in range(6):\n",
    "# \tprint(f\"({epoch}) a - w: {w.item()}, w.grad: {w.grad}; b: {b.item()}, b.grad: {b.grad}; loss: {loss}\")\n",
    "# \trecords.append({\"epoch\": epoch, \"step\": \"a\", \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()})\n",
    "# \tpreds = X.mm(w) + b        # 前向\n",
    "# \tprint(f\"({epoch}) b - w: {w.item()}, w.grad: {w.grad}; b: {b.item()}, b.grad: {b.grad}; loss: {loss}\")\n",
    "# \trecords.append({\"epoch\": epoch, \"step\": \"b\", \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()})\n",
    "# \tloss = loss_fn(preds, y)\n",
    "# \tprint(f\"({epoch}) c - w: {w.item()}, w.grad: {w.grad}; b: {b.item()}, b.grad: {b.grad}; loss: {loss}\")\n",
    "# \trecords.append({\"epoch\": epoch, \"step\": \"c\", \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()})\n",
    "# \topt.zero_grad()\n",
    "# \tprint(f\"({epoch}) d - w: {w.item()}, w.grad: {w.grad}; b: {b.item()}, b.grad: {b.grad}; loss: {loss}\")\n",
    "# \trecords.append({\"epoch\": epoch, \"step\": \"d\", \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()})\n",
    "# \tloss.backward()             # 自动计算梯度\n",
    "# \tprint(f\"({epoch}) e - w: {w.item()}, w.grad: {w.grad}; b: {b.item()}, b.grad: {b.grad}; loss: {loss}\")\n",
    "# \trecords.append({\"epoch\": epoch, \"step\": \"e\", \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()})\n",
    "# \topt.step()                  # 参数更新由优化器完成\n",
    "# \tprint(f\"({epoch}) f - w: {w.item()}, w.grad: {w.grad}; b: {b.item()}, b.grad: {b.grad}; loss: {loss}\")\n",
    "# \trecords.append({\"epoch\": epoch, \"step\": \"f\", \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()})\n",
    "# records_df = pl.DataFrame(records)\n",
    "\n",
    "records, loss, preds = [], torch.tensor(float('nan')), None\n",
    "for epoch in range(6):\n",
    "\trecords.append(recouter(print, epoch, 'a', w, b, loss, 0))\n",
    "\tpreds = X.mm(w) + b        # 前向\n",
    "\trecords.append(recouter(print, epoch, 'b', w, b, loss, 0))\n",
    "\tloss = loss_fn(preds, y)\n",
    "\trecords.append(recouter(print, epoch, 'c', w, b, loss, 0))\n",
    "\topt.zero_grad()\n",
    "\trecords.append(recouter(print, epoch, 'd', w, b, loss, 0))\n",
    "\tloss.backward()             # 自动计算梯度\n",
    "\trecords.append(recouter(print, epoch, 'e', w, b, loss, 0))\n",
    "\topt.step()                  # 参数更新由优化器完成\n",
    "\trecords.append(recouter(print, epoch, 'f', w, b, loss, 0))\n",
    "records_df = pl.DataFrame(records)\n",
    "\n",
    "print(\"params (bias, weight):\", b.item(), w.item())\n",
    "print(\"final MSE:\", loss.item())\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e5bd10-8b5c-48c1-aa4a-057f55b068cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (36, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;a&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;b&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;c&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;d&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;e&quot;</td><td>0.0</td><td>-86.795395</td><td>0.0</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>5</td><td>&quot;b&quot;</td><td>4.165996</td><td>-79.91571</td><td>0.15671</td><td>-2.809649</td><td>1681.296265</td></tr><tr><td>5</td><td>&quot;c&quot;</td><td>4.165996</td><td>-79.91571</td><td>0.15671</td><td>-2.809649</td><td>1618.006592</td></tr><tr><td>5</td><td>&quot;d&quot;</td><td>4.165996</td><td>null</td><td>0.15671</td><td>null</td><td>1618.006592</td></tr><tr><td>5</td><td>&quot;e&quot;</td><td>4.165996</td><td>-78.283012</td><td>0.15671</td><td>-2.657864</td><td>1618.006592</td></tr><tr><td>5</td><td>&quot;f&quot;</td><td>4.948826</td><td>-78.283012</td><td>0.183288</td><td>-2.657864</td><td>1618.006592</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (36, 7)\n",
       "┌───────┬──────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---  ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str  ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 0     ┆ a    ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ b    ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ c    ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ d    ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ e    ┆ 0.0      ┆ -86.795395 ┆ 0.0      ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ …     ┆ …    ┆ …        ┆ …          ┆ …        ┆ …         ┆ …           │\n",
       "│ 5     ┆ b    ┆ 4.165996 ┆ -79.91571  ┆ 0.15671  ┆ -2.809649 ┆ 1681.296265 │\n",
       "│ 5     ┆ c    ┆ 4.165996 ┆ -79.91571  ┆ 0.15671  ┆ -2.809649 ┆ 1618.006592 │\n",
       "│ 5     ┆ d    ┆ 4.165996 ┆ null       ┆ 0.15671  ┆ null      ┆ 1618.006592 │\n",
       "│ 5     ┆ e    ┆ 4.165996 ┆ -78.283012 ┆ 0.15671  ┆ -2.657864 ┆ 1618.006592 │\n",
       "│ 5     ┆ f    ┆ 4.948826 ┆ -78.283012 ┆ 0.183288 ┆ -2.657864 ┆ 1618.006592 │\n",
       "└───────┴──────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50028137-62e6-4839-8359-a2e28b4d4b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;a&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;b&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;c&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;d&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;e&quot;</td><td>0.0</td><td>-86.795395</td><td>0.0</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;f&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 7)\n",
       "┌───────┬──────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---  ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str  ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 0     ┆ a    ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ b    ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ c    ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ d    ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ e    ┆ 0.0      ┆ -86.795395 ┆ 0.0      ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 0     ┆ f    ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "└───────┴──────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df.filter(pl.col(\"epoch\") == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36acefb1-4996-44f8-afe8-f6687b702f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>&quot;a&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>1</td><td>&quot;b&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>1</td><td>&quot;c&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;d&quot;</td><td>0.867954</td><td>null</td><td>0.034696</td><td>null</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;e&quot;</td><td>0.867954</td><td>-85.02166</td><td>0.034696</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;f&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 7)\n",
       "┌───────┬──────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---  ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str  ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 1     ┆ a    ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 1     ┆ b    ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 1     ┆ c    ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1887.662476 │\n",
       "│ 1     ┆ d    ┆ 0.867954 ┆ null       ┆ 0.034696 ┆ null      ┆ 1887.662476 │\n",
       "│ 1     ┆ e    ┆ 0.867954 ┆ -85.02166  ┆ 0.034696 ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 1     ┆ f    ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "└───────┴──────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df.filter(pl.col(\"epoch\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99fc93b9-7e04-43b4-b4c6-c59b70ddea69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>&quot;a&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>2</td><td>&quot;b&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>2</td><td>&quot;c&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;d&quot;</td><td>1.718171</td><td>null</td><td>0.06766</td><td>null</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;e&quot;</td><td>1.718171</td><td>-83.284286</td><td>0.06766</td><td>-3.128763</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;f&quot;</td><td>2.551013</td><td>-83.284286</td><td>0.098948</td><td>-3.128763</td><td>1816.008301</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 7)\n",
       "┌───────┬──────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---  ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str  ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 2     ┆ a    ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 2     ┆ b    ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 2     ┆ c    ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1816.008301 │\n",
       "│ 2     ┆ d    ┆ 1.718171 ┆ null       ┆ 0.06766  ┆ null      ┆ 1816.008301 │\n",
       "│ 2     ┆ e    ┆ 1.718171 ┆ -83.284286 ┆ 0.06766  ┆ -3.128763 ┆ 1816.008301 │\n",
       "│ 2     ┆ f    ┆ 2.551013 ┆ -83.284286 ┆ 0.098948 ┆ -3.128763 ┆ 1816.008301 │\n",
       "└───────┴──────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df.filter(pl.col(\"epoch\") == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc3466f-c031-4106-8816-f45b9554cc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>3</td><td>&quot;a&quot;</td><td>2.551013</td><td>-83.284286</td><td>0.098948</td><td>-3.128763</td><td>1816.008301</td></tr><tr><td>3</td><td>&quot;b&quot;</td><td>2.551013</td><td>-83.284286</td><td>0.098948</td><td>-3.128763</td><td>1816.008301</td></tr><tr><td>3</td><td>&quot;c&quot;</td><td>2.551013</td><td>-83.284286</td><td>0.098948</td><td>-3.128763</td><td>1747.258911</td></tr><tr><td>3</td><td>&quot;d&quot;</td><td>2.551013</td><td>null</td><td>0.098948</td><td>null</td><td>1747.258911</td></tr><tr><td>3</td><td>&quot;e&quot;</td><td>2.551013</td><td>-81.582542</td><td>0.098948</td><td>-2.966566</td><td>1747.258911</td></tr><tr><td>3</td><td>&quot;f&quot;</td><td>3.366839</td><td>-81.582542</td><td>0.128613</td><td>-2.966566</td><td>1747.258911</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 7)\n",
       "┌───────┬──────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---  ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str  ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 3     ┆ a    ┆ 2.551013 ┆ -83.284286 ┆ 0.098948 ┆ -3.128763 ┆ 1816.008301 │\n",
       "│ 3     ┆ b    ┆ 2.551013 ┆ -83.284286 ┆ 0.098948 ┆ -3.128763 ┆ 1816.008301 │\n",
       "│ 3     ┆ c    ┆ 2.551013 ┆ -83.284286 ┆ 0.098948 ┆ -3.128763 ┆ 1747.258911 │\n",
       "│ 3     ┆ d    ┆ 2.551013 ┆ null       ┆ 0.098948 ┆ null      ┆ 1747.258911 │\n",
       "│ 3     ┆ e    ┆ 2.551013 ┆ -81.582542 ┆ 0.098948 ┆ -2.966566 ┆ 1747.258911 │\n",
       "│ 3     ┆ f    ┆ 3.366839 ┆ -81.582542 ┆ 0.128613 ┆ -2.966566 ┆ 1747.258911 │\n",
       "└───────┴──────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df.filter(pl.col(\"epoch\") == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc189fdd-2042-457a-9927-587a64b817a4",
   "metadata": {},
   "source": [
    "# Model Class style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4bd3f-920e-4c6a-adfa-db2e710b999e",
   "metadata": {},
   "source": [
    "## One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af36b8d-4166-4457-b16f-0e1fb574a48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max abs pred diff: 0.0\n",
      "loss diff: 0.0\n",
      "=== bare ===\n",
      "(0) a (bare) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) b (bare) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) c (bare) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) d (bare) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) e (bare) - w: 0.0, w.grad: tensor([[-86.7954]]); b: 0.0, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(0) f (bare) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "=== mod ===\n",
      "(0) a (mod) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) b (mod) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) c (mod) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) d (mod) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) e (mod) - w: 0.0, w.grad: tensor([[-86.7954]]); b: 0.0, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(0) f (mod) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "=== bare ===\n",
      "(1) a (bare) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) b (bare) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) c (bare) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1887.6624755859375\n",
      "(1) d (bare) - w: 0.8679539561271667, w.grad: None; b: 0.03469603508710861, b.grad: None; loss: 1887.6624755859375\n",
      "(1) e (bare) - w: 0.8679539561271667, w.grad: tensor([[-85.0217]]); b: 0.03469603508710861, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(1) f (bare) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "=== mod ===\n",
      "(1) a (mod) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) b (mod) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) c (mod) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1887.6624755859375\n",
      "(1) d (mod) - w: 0.8679539561271667, w.grad: None; b: 0.03469603508710861, b.grad: None; loss: 1887.6624755859375\n",
      "(1) e (mod) - w: 0.8679539561271667, w.grad: tensor([[-85.0217]]); b: 0.03469603508710861, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(1) f (mod) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "=== bare ===\n",
      "(2) a (bare) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) b (bare) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) c (bare) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1816.00830078125\n",
      "(2) d (bare) - w: 1.7181705236434937, w.grad: None; b: 0.06765993684530258, b.grad: None; loss: 1816.00830078125\n",
      "(2) e (bare) - w: 1.7181705236434937, w.grad: tensor([[-83.2843]]); b: 0.06765993684530258, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(2) f (bare) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "=== mod ===\n",
      "(2) a (mod) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) b (mod) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) c (mod) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1816.00830078125\n",
      "(2) d (mod) - w: 1.7181705236434937, w.grad: None; b: 0.06765993684530258, b.grad: None; loss: 1816.00830078125\n",
      "(2) e (mod) - w: 1.7181705236434937, w.grad: tensor([[-83.2843]]); b: 0.06765993684530258, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(2) f (mod) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "=== bare ===\n",
      "(3) a (bare) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(3) b (bare) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(3) c (bare) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1747.2589111328125\n",
      "(3) d (bare) - w: 2.551013469696045, w.grad: None; b: 0.09894756227731705, b.grad: None; loss: 1747.2589111328125\n",
      "(3) e (bare) - w: 2.551013469696045, w.grad: tensor([[-81.5825]]); b: 0.09894756227731705, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(3) f (bare) - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "=== mod ===\n",
      "(3) a (mod) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(3) b (mod) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(3) c (mod) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1747.2589111328125\n",
      "(3) d (mod) - w: 2.551013469696045, w.grad: None; b: 0.09894756227731705, b.grad: None; loss: 1747.2589111328125\n",
      "(3) e (mod) - w: 2.551013469696045, w.grad: tensor([[-81.5825]]); b: 0.09894756227731705, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(3) f (mod) - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "=== bare ===\n",
      "(4) a (bare) - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(4) b (bare) - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(4) c (bare) - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1681.2962646484375\n",
      "(4) d (bare) - w: 3.3668389320373535, w.grad: None; b: 0.12861321866512299, b.grad: None; loss: 1681.2962646484375\n",
      "(4) e (bare) - w: 3.3668389320373535, w.grad: tensor([[-79.9157]]); b: 0.12861321866512299, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(4) f (bare) - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "=== mod ===\n",
      "(4) a (mod) - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(4) b (mod) - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1747.2589111328125\n",
      "(4) c (mod) - w: 3.3668389320373535, w.grad: tensor([[-81.5825]]); b: 0.12861321866512299, b.grad: tensor([-2.9666]); loss: 1681.2962646484375\n",
      "(4) d (mod) - w: 3.3668389320373535, w.grad: None; b: 0.12861321866512299, b.grad: None; loss: 1681.2962646484375\n",
      "(4) e (mod) - w: 3.3668389320373535, w.grad: tensor([[-79.9157]]); b: 0.12861321866512299, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(4) f (mod) - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "=== bare ===\n",
      "(5) a (bare) - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(5) b (bare) - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(5) c (bare) - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1618.006591796875\n",
      "(5) d (bare) - w: 4.165996074676514, w.grad: None; b: 0.1567097008228302, b.grad: None; loss: 1618.006591796875\n",
      "(5) e (bare) - w: 4.165996074676514, w.grad: tensor([[-78.2830]]); b: 0.1567097008228302, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "(5) f (bare) - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "=== mod ===\n",
      "(5) a (mod) - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(5) b (mod) - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1681.2962646484375\n",
      "(5) c (mod) - w: 4.165996074676514, w.grad: tensor([[-79.9157]]); b: 0.1567097008228302, b.grad: tensor([-2.8096]); loss: 1618.006591796875\n",
      "(5) d (mod) - w: 4.165996074676514, w.grad: None; b: 0.1567097008228302, b.grad: None; loss: 1618.006591796875\n",
      "(5) e (mod) - w: 4.165996074676514, w.grad: tensor([[-78.2830]]); b: 0.1567097008228302, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "(5) f (mod) - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "=== bare ===\n",
      "(6) a (bare) - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "(6) b (bare) - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "(6) c (bare) - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1557.2813720703125\n",
      "(6) d (bare) - w: 4.948826313018799, w.grad: None; b: 0.1832883358001709, b.grad: None; loss: 1557.2813720703125\n",
      "(6) e (bare) - w: 4.948826313018799, w.grad: tensor([[-76.6838]]); b: 0.1832883358001709, b.grad: tensor([-2.5111]); loss: 1557.2813720703125\n",
      "(6) f (bare) - w: 5.715663909912109, w.grad: tensor([[-76.6838]]); b: 0.20839901268482208, b.grad: tensor([-2.5111]); loss: 1557.2813720703125\n",
      "=== mod ===\n",
      "(6) a (mod) - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "(6) b (mod) - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1618.006591796875\n",
      "(6) c (mod) - w: 4.948826313018799, w.grad: tensor([[-78.2830]]); b: 0.1832883358001709, b.grad: tensor([-2.6579]); loss: 1557.2813720703125\n",
      "(6) d (mod) - w: 4.948826313018799, w.grad: None; b: 0.1832883358001709, b.grad: None; loss: 1557.2813720703125\n",
      "(6) e (mod) - w: 4.948826313018799, w.grad: tensor([[-76.6838]]); b: 0.1832883358001709, b.grad: tensor([-2.5111]); loss: 1557.2813720703125\n",
      "(6) f (mod) - w: 5.715663909912109, w.grad: tensor([[-76.6838]]); b: 0.20839901268482208, b.grad: tensor([-2.5111]); loss: 1557.2813720703125\n",
      "=== bare ===\n",
      "(7) a (bare) - w: 5.715663909912109, w.grad: tensor([[-76.6838]]); b: 0.20839901268482208, b.grad: tensor([-2.5111]); loss: 1557.2813720703125\n",
      "(7) b (bare) - w: 5.715663909912109, w.grad: tensor([[-76.6838]]); b: 0.20839901268482208, b.grad: tensor([-2.5111]); loss: 1557.2813720703125\n",
      "(7) c (bare) - w: 5.715663909912109, w.grad: tensor([[-76.6838]]); b: 0.20839901268482208, b.grad: tensor([-2.5111]); loss: 1499.0167236328125\n",
      "(7) d (bare) - w: 5.715663909912109, w.grad: None; b: 0.20839901268482208, b.grad: None; loss: 1499.0167236328125\n",
      "(7) e (bare) - w: 5.715663909912109, w.grad: tensor([[-75.1174]]); b: 0.20839901268482208, b.grad: tensor([-2.3691]); loss: 1499.0167236328125\n",
      "(7) f (bare) - w: 6.466837406158447, w.grad: tensor([[-75.1174]]); b: 0.23209021985530853, b.grad: tensor([-2.3691]); loss: 1499.0167236328125\n",
      "=== mod ===\n",
      "(7) a (mod) - w: 5.715663909912109, w.grad: tensor([[-76.6838]]); b: 0.20839901268482208, b.grad: tensor([-2.5111]); loss: 1557.2813720703125\n",
      "(7) b (mod) - w: 5.715663909912109, w.grad: tensor([[-76.6838]]); b: 0.20839901268482208, b.grad: tensor([-2.5111]); loss: 1557.2813720703125\n",
      "(7) c (mod) - w: 5.715663909912109, w.grad: tensor([[-76.6838]]); b: 0.20839901268482208, b.grad: tensor([-2.5111]); loss: 1499.0167236328125\n",
      "(7) d (mod) - w: 5.715663909912109, w.grad: None; b: 0.20839901268482208, b.grad: None; loss: 1499.0167236328125\n",
      "(7) e (mod) - w: 5.715663909912109, w.grad: tensor([[-75.1174]]); b: 0.20839901268482208, b.grad: tensor([-2.3691]); loss: 1499.0167236328125\n",
      "(7) f (mod) - w: 6.466837406158447, w.grad: tensor([[-75.1174]]); b: 0.23209021985530853, b.grad: tensor([-2.3691]); loss: 1499.0167236328125\n",
      "=== bare ===\n",
      "(8) a (bare) - w: 6.466837406158447, w.grad: tensor([[-75.1174]]); b: 0.23209021985530853, b.grad: tensor([-2.3691]); loss: 1499.0167236328125\n",
      "(8) b (bare) - w: 6.466837406158447, w.grad: tensor([[-75.1174]]); b: 0.23209021985530853, b.grad: tensor([-2.3691]); loss: 1499.0167236328125\n",
      "(8) c (bare) - w: 6.466837406158447, w.grad: tensor([[-75.1174]]); b: 0.23209021985530853, b.grad: tensor([-2.3691]); loss: 1443.1123046875\n",
      "(8) d (bare) - w: 6.466837406158447, w.grad: None; b: 0.23209021985530853, b.grad: None; loss: 1443.1123046875\n",
      "(8) e (bare) - w: 6.466837406158447, w.grad: tensor([[-73.5830]]); b: 0.23209021985530853, b.grad: tensor([-2.2319]); loss: 1443.1123046875\n",
      "(8) f (bare) - w: 7.202667713165283, w.grad: tensor([[-73.5830]]); b: 0.2544090747833252, b.grad: tensor([-2.2319]); loss: 1443.1123046875\n",
      "=== mod ===\n",
      "(8) a (mod) - w: 6.466837406158447, w.grad: tensor([[-75.1174]]); b: 0.23209021985530853, b.grad: tensor([-2.3691]); loss: 1499.0167236328125\n",
      "(8) b (mod) - w: 6.466837406158447, w.grad: tensor([[-75.1174]]); b: 0.23209021985530853, b.grad: tensor([-2.3691]); loss: 1499.0167236328125\n",
      "(8) c (mod) - w: 6.466837406158447, w.grad: tensor([[-75.1174]]); b: 0.23209021985530853, b.grad: tensor([-2.3691]); loss: 1443.1123046875\n",
      "(8) d (mod) - w: 6.466837406158447, w.grad: None; b: 0.23209021985530853, b.grad: None; loss: 1443.1123046875\n",
      "(8) e (mod) - w: 6.466837406158447, w.grad: tensor([[-73.5830]]); b: 0.23209021985530853, b.grad: tensor([-2.2319]); loss: 1443.1123046875\n",
      "(8) f (mod) - w: 7.202667713165283, w.grad: tensor([[-73.5830]]); b: 0.2544090747833252, b.grad: tensor([-2.2319]); loss: 1443.1123046875\n",
      "=== bare ===\n",
      "(9) a (bare) - w: 7.202667713165283, w.grad: tensor([[-73.5830]]); b: 0.2544090747833252, b.grad: tensor([-2.2319]); loss: 1443.1123046875\n",
      "(9) b (bare) - w: 7.202667713165283, w.grad: tensor([[-73.5830]]); b: 0.2544090747833252, b.grad: tensor([-2.2319]); loss: 1443.1123046875\n",
      "(9) c (bare) - w: 7.202667713165283, w.grad: tensor([[-73.5830]]); b: 0.2544090747833252, b.grad: tensor([-2.2319]); loss: 1389.47216796875\n",
      "(9) d (bare) - w: 7.202667713165283, w.grad: None; b: 0.2544090747833252, b.grad: None; loss: 1389.47216796875\n",
      "(9) e (bare) - w: 7.202667713165283, w.grad: tensor([[-72.0801]]); b: 0.2544090747833252, b.grad: tensor([-2.0992]); loss: 1389.47216796875\n",
      "(9) f (bare) - w: 7.923468589782715, w.grad: tensor([[-72.0801]]); b: 0.27540138363838196, b.grad: tensor([-2.0992]); loss: 1389.47216796875\n",
      "=== mod ===\n",
      "(9) a (mod) - w: 7.202667713165283, w.grad: tensor([[-73.5830]]); b: 0.2544090747833252, b.grad: tensor([-2.2319]); loss: 1443.1123046875\n",
      "(9) b (mod) - w: 7.202667713165283, w.grad: tensor([[-73.5830]]); b: 0.2544090747833252, b.grad: tensor([-2.2319]); loss: 1443.1123046875\n",
      "(9) c (mod) - w: 7.202667713165283, w.grad: tensor([[-73.5830]]); b: 0.2544090747833252, b.grad: tensor([-2.2319]); loss: 1389.47216796875\n",
      "(9) d (mod) - w: 7.202667713165283, w.grad: None; b: 0.2544090747833252, b.grad: None; loss: 1389.47216796875\n",
      "(9) e (mod) - w: 7.202667713165283, w.grad: tensor([[-72.0801]]); b: 0.2544090747833252, b.grad: tensor([-2.0992]); loss: 1389.47216796875\n",
      "(9) f (mod) - w: 7.923468589782715, w.grad: tensor([[-72.0801]]); b: 0.27540138363838196, b.grad: tensor([-2.0992]); loss: 1389.47216796875\n",
      "final bias diff: 0.0\n",
      "final weight diff: 0.0\n",
      "final loss diff: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (120, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;a (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;b (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;c (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;d (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;e (bare)&quot;</td><td>0.0</td><td>-86.795395</td><td>0.0</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9</td><td>&quot;b (mod)&quot;</td><td>7.202668</td><td>-73.583015</td><td>0.254409</td><td>-2.231884</td><td>1443.112305</td></tr><tr><td>9</td><td>&quot;c (mod)&quot;</td><td>7.202668</td><td>-73.583015</td><td>0.254409</td><td>-2.231884</td><td>1389.472168</td></tr><tr><td>9</td><td>&quot;d (mod)&quot;</td><td>7.202668</td><td>null</td><td>0.254409</td><td>null</td><td>1389.472168</td></tr><tr><td>9</td><td>&quot;e (mod)&quot;</td><td>7.202668</td><td>-72.080109</td><td>0.254409</td><td>-2.09923</td><td>1389.472168</td></tr><tr><td>9</td><td>&quot;f (mod)&quot;</td><td>7.923469</td><td>-72.080109</td><td>0.275401</td><td>-2.09923</td><td>1389.472168</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (120, 7)\n",
       "┌───────┬──────────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step     ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---      ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str      ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 0     ┆ a (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ b (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ c (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ d (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ e (bare) ┆ 0.0      ┆ -86.795395 ┆ 0.0      ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ …     ┆ …        ┆ …        ┆ …          ┆ …        ┆ …         ┆ …           │\n",
       "│ 9     ┆ b (mod)  ┆ 7.202668 ┆ -73.583015 ┆ 0.254409 ┆ -2.231884 ┆ 1443.112305 │\n",
       "│ 9     ┆ c (mod)  ┆ 7.202668 ┆ -73.583015 ┆ 0.254409 ┆ -2.231884 ┆ 1389.472168 │\n",
       "│ 9     ┆ d (mod)  ┆ 7.202668 ┆ null       ┆ 0.254409 ┆ null      ┆ 1389.472168 │\n",
       "│ 9     ┆ e (mod)  ┆ 7.202668 ┆ -72.080109 ┆ 0.254409 ┆ -2.09923  ┆ 1389.472168 │\n",
       "│ 9     ┆ f (mod)  ┆ 7.923469 ┆ -72.080109 ┆ 0.275401 ┆ -2.09923  ┆ 1389.472168 │\n",
       "└───────┴──────────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# 数据\n",
    "X_np, y_np = make_regression(n_samples=100, n_features=1, noise=10.0, random_state=0)\n",
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# 裸实现初始化\n",
    "w = torch.zeros((1,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# 封装模型\n",
    "class LinearModel(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.w = torch.nn.Parameter(torch.zeros(1,1))\n",
    "\t\tself.b = torch.nn.Parameter(torch.zeros(1))\n",
    "\tdef forward(self, x):\n",
    "\t\treturn x.mm(self.w) + self.b\n",
    "\n",
    "model = LinearModel()\n",
    "\n",
    "# 将裸参数拷贝到 model（确保完全相同起点）\n",
    "with torch.no_grad():\n",
    "\tmodel.w.copy_(w)\n",
    "\tmodel.b.copy_(b)\n",
    "\n",
    "# 验证在相同输入下预测和损失一致\n",
    "preds_bare = X.mm(w) + b\n",
    "preds_mod  = model(X)\n",
    "print('max abs pred diff:', (preds_bare - preds_mod).abs().max().item())\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "print('loss diff:', abs(loss_fn(preds_bare, y).item() - loss_fn(preds_mod, y).item()))\n",
    "\n",
    "# 训练两者（完全相同超参数）\n",
    "opt_bare = torch.optim.SGD([w, b], lr=0.01)\n",
    "opt_mod  = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# for epoch in range(1000):\n",
    "# \t# 裸实现 step\n",
    "# \tp_bare = X.mm(w) + b\n",
    "# \tloss_bare = loss_fn(p_bare, y)\n",
    "# \topt_bare.zero_grad(); loss_bare.backward(); opt_bare.step()\n",
    "# \t\n",
    "# \t# 模型实现 step\n",
    "# \tp_mod = model(X)\n",
    "# \tloss_mod = loss_fn(p_mod, y)\n",
    "# \topt_mod.zero_grad(); loss_mod.backward(); opt_mod.step()\n",
    "\n",
    "\n",
    "recorder = lambda epoch,step,w,b,loss: {\"epoch\": epoch, \"step\": step, \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()}\n",
    "recouter = lambda print_fn,epoch,step,w,b,loss,rti=-1: [\n",
    "\tr := recorder(epoch,step,w,b,loss), \n",
    "\tx := type('',(),r)(), \n",
    "\tprint_fn(f\"({x.epoch}) {x.step} - w: {x.w}, w.grad: {getattr(x,'w.grad')}; b: {x.b}, b.grad: {getattr(x,'b.grad')}; loss: {x.loss}\"), \n",
    "\tx][rti]\n",
    "\n",
    "\n",
    "records = []\n",
    "loss_bare, p_bare = loss_mod, p_mod = torch.tensor(float('nan')), None\n",
    "for epoch in range(10):\n",
    "\t\n",
    "\t# 裸实现 step\n",
    "\tprint(\"=== bare ===\")                         ; records.append(recouter(print, epoch, 'a (bare)', w, b, loss_bare, 0))\n",
    "\tp_bare = X.mm(w) + b                          ; records.append(recouter(print, epoch, 'b (bare)', w, b, loss_bare, 0))\n",
    "\tloss_bare = loss_fn(p_bare, y)                ; records.append(recouter(print, epoch, 'c (bare)', w, b, loss_bare, 0))\n",
    "\topt_bare.zero_grad()                          ; records.append(recouter(print, epoch, 'd (bare)', w, b, loss_bare, 0))\n",
    "\tloss_bare.backward()                          ; records.append(recouter(print, epoch, 'e (bare)', w, b, loss_bare, 0))\n",
    "\topt_bare.step()                               ; records.append(recouter(print, epoch, 'f (bare)', w, b, loss_bare, 0))\n",
    "\t\n",
    "\t# 模型实现 step\n",
    "\tprint(\"=== mod ===\")                ; records.append(recouter(print, epoch, 'a (mod)', model.w, model.b, loss_mod, 0))\n",
    "\tp_mod = model(X)                    ; records.append(recouter(print, epoch, 'b (mod)', model.w, model.b, loss_mod, 0))\n",
    "\tloss_mod = loss_fn(p_mod, y)        ; records.append(recouter(print, epoch, 'c (mod)', model.w, model.b, loss_mod, 0))\n",
    "\topt_mod.zero_grad()                 ; records.append(recouter(print, epoch, 'd (mod)', model.w, model.b, loss_mod, 0))\n",
    "\tloss_mod.backward()                 ; records.append(recouter(print, epoch, 'e (mod)', model.w, model.b, loss_mod, 0))\n",
    "\topt_mod.step()                      ; records.append(recouter(print, epoch, 'f (mod)', model.w, model.b, loss_mod, 0))\n",
    "\n",
    "import polars as pl\n",
    "records_df = pl.DataFrame(records)\n",
    "\n",
    "# 比较最终参数与损失\n",
    "print('final bias diff:', abs(b.item() - model.b.item()))\n",
    "print('final weight diff:', (w - model.w).abs().max().item())\n",
    "print('final loss diff:', abs(loss_bare.item() - loss_mod.item()))\n",
    "\n",
    "records_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc06d4-6d3b-4c10-b73d-d1a0911179ac",
   "metadata": {},
   "source": [
    "## Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed5cd30-b0a2-4f94-9b39-54227066a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.35955316]\n",
      " [ 0.97663904]\n",
      " [ 0.40234164]\n",
      " [-0.81314628]\n",
      " [-0.88778575]\n",
      " [ 0.44386323]\n",
      " [-0.97727788]\n",
      " [ 0.42833187]\n",
      " [ 0.20827498]\n",
      " [-0.31155253]]\n",
      "[-19.95588561  21.33977271  11.55689458 -16.34206917 -35.70063849\n",
      "  27.99539547 -56.32353045  17.61041414  21.45106196 -22.35286466]\n",
      "tensor([[-0.3596],\n",
      "        [ 0.9766],\n",
      "        [ 0.4023],\n",
      "        [-0.8131],\n",
      "        [-0.8878],\n",
      "        [ 0.4439],\n",
      "        [-0.9773],\n",
      "        [ 0.4283],\n",
      "        [ 0.2083],\n",
      "        [-0.3116]])\n",
      "tensor([[-19.9559],\n",
      "        [ 21.3398],\n",
      "        [ 11.5569],\n",
      "        [-16.3421],\n",
      "        [-35.7006],\n",
      "        [ 27.9954],\n",
      "        [-56.3235],\n",
      "        [ 17.6104],\n",
      "        [ 21.4511],\n",
      "        [-22.3529]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# 数据\n",
    "X_np, y_np = make_regression(n_samples=100, n_features=1, noise=10.0, random_state=0)\n",
    "X = torch.tensor(X_np, dtype=torch.float32)\n",
    "y = torch.tensor(y_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(X_np[:10])\n",
    "print(y_np[:10])\n",
    "print(X[:10])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59411f4f-49ea-478f-aad2-afd66ff562f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max abs pred diff: 0.0\n",
      "loss diff: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.01\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.01\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 裸实现初始化\n",
    "w = torch.zeros((1,1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "# 封装模型\n",
    "class LinearModel(torch.nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.w = torch.nn.Parameter(torch.zeros(1,1))\n",
    "\t\tself.b = torch.nn.Parameter(torch.zeros(1))\n",
    "\tdef forward(self, x):\n",
    "\t\treturn x.mm(self.w) + self.b\n",
    "\n",
    "model = LinearModel()\n",
    "\n",
    "# 将裸参数拷贝到 model（确保完全相同起点）\n",
    "with torch.no_grad():\n",
    "\tmodel.w.copy_(w)\n",
    "\tmodel.b.copy_(b)\n",
    "\n",
    "# 验证在相同输入下预测和损失一致\n",
    "preds_bare = X.mm(w) + b\n",
    "preds_mod  = model(X)\n",
    "print('max abs pred diff:', (preds_bare - preds_mod).abs().max().item())\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "print('loss diff:', abs(loss_fn(preds_bare, y).item() - loss_fn(preds_mod, y).item()))\n",
    "\n",
    "# 训练两者（完全相同超参数）\n",
    "opt_bare = torch.optim.SGD([w, b], lr=0.01)\n",
    "opt_mod  = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "opt_bare, opt_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f42278-618b-4c3e-b882-f0ff50221d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = lambda epoch,step,w,b,loss: {\"epoch\": epoch, \"step\": step, \"w\": w.item(), \"w.grad\": w.grad, \"b\": b.item(), \"b.grad\": b.grad, \"loss\": loss.item()}\n",
    "recouter = lambda print_fn,epoch,step,w,b,loss,rti=-1: [\n",
    "\tr := recorder(epoch,step,w,b,loss), \n",
    "\tx := type('',(),r)(), \n",
    "\tprint_fn(f\"({x.epoch}) {x.step} - w: {x.w}, w.grad: {getattr(x,'w.grad')}; b: {x.b}, b.grad: {getattr(x,'b.grad')}; loss: {x.loss}\"), \n",
    "\tx][rti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b07255d-b3a8-4255-9200-91ad6950d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bare ===\n",
      "(0) a (bare) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) b (bare) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) c (bare) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) d (bare) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) e (bare) - w: 0.0, w.grad: tensor([[-86.7954]]); b: 0.0, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(0) f (bare) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "=== mod ===\n",
      "(0) a (mod) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) b (mod) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: nan\n",
      "(0) c (mod) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) d (mod) - w: 0.0, w.grad: None; b: 0.0, b.grad: None; loss: 1962.344482421875\n",
      "(0) e (mod) - w: 0.0, w.grad: tensor([[-86.7954]]); b: 0.0, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(0) f (mod) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "=== bare ===\n",
      "(1) a (bare) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) b (bare) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) c (bare) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1887.6624755859375\n",
      "(1) d (bare) - w: 0.8679539561271667, w.grad: None; b: 0.03469603508710861, b.grad: None; loss: 1887.6624755859375\n",
      "(1) e (bare) - w: 0.8679539561271667, w.grad: tensor([[-85.0217]]); b: 0.03469603508710861, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(1) f (bare) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "=== mod ===\n",
      "(1) a (mod) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) b (mod) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1962.344482421875\n",
      "(1) c (mod) - w: 0.8679539561271667, w.grad: tensor([[-86.7954]]); b: 0.03469603508710861, b.grad: tensor([-3.4696]); loss: 1887.6624755859375\n",
      "(1) d (mod) - w: 0.8679539561271667, w.grad: None; b: 0.03469603508710861, b.grad: None; loss: 1887.6624755859375\n",
      "(1) e (mod) - w: 0.8679539561271667, w.grad: tensor([[-85.0217]]); b: 0.03469603508710861, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(1) f (mod) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "=== bare ===\n",
      "(2) a (bare) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) b (bare) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) c (bare) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1816.00830078125\n",
      "(2) d (bare) - w: 1.7181705236434937, w.grad: None; b: 0.06765993684530258, b.grad: None; loss: 1816.00830078125\n",
      "(2) e (bare) - w: 1.7181705236434937, w.grad: tensor([[-83.2843]]); b: 0.06765993684530258, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(2) f (bare) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "=== mod ===\n",
      "(2) a (mod) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) b (mod) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1887.6624755859375\n",
      "(2) c (mod) - w: 1.7181705236434937, w.grad: tensor([[-85.0217]]); b: 0.06765993684530258, b.grad: tensor([-3.2964]); loss: 1816.00830078125\n",
      "(2) d (mod) - w: 1.7181705236434937, w.grad: None; b: 0.06765993684530258, b.grad: None; loss: 1816.00830078125\n",
      "(2) e (mod) - w: 1.7181705236434937, w.grad: tensor([[-83.2843]]); b: 0.06765993684530258, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "(2) f (mod) - w: 2.551013469696045, w.grad: tensor([[-83.2843]]); b: 0.09894756227731705, b.grad: tensor([-3.1288]); loss: 1816.00830078125\n",
      "final bias diff: 0.0\n",
      "final weight diff: 0.0\n",
      "final loss diff: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.01\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.01\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for epoch in range(1000):\n",
    "# \t# 裸实现 step\n",
    "# \tp_bare = X.mm(w) + b\n",
    "# \tloss_bare = loss_fn(p_bare, y)\n",
    "# \topt_bare.zero_grad(); loss_bare.backward(); opt_bare.step()\n",
    "# \t\n",
    "# \t# 模型实现 step\n",
    "# \tp_mod = model(X)\n",
    "# \tloss_mod = loss_fn(p_mod, y)\n",
    "# \topt_mod.zero_grad(); loss_mod.backward(); opt_mod.step()\n",
    "\n",
    "records = []\n",
    "loss_bare, p_bare = loss_mod, p_mod = torch.tensor(float('nan')), None\n",
    "for epoch in range(3):\n",
    "\t\n",
    "\t# 裸实现 step\n",
    "\tprint(\"=== bare ===\")                         ; records.append(recouter(print, epoch, 'a (bare)', w, b, loss_bare, 0))\n",
    "\tp_bare = X.mm(w) + b                          ; records.append(recouter(print, epoch, 'b (bare)', w, b, loss_bare, 0))\n",
    "\tloss_bare = loss_fn(p_bare, y)                ; records.append(recouter(print, epoch, 'c (bare)', w, b, loss_bare, 0))\n",
    "\topt_bare.zero_grad()                          ; records.append(recouter(print, epoch, 'd (bare)', w, b, loss_bare, 0))\n",
    "\tloss_bare.backward()                          ; records.append(recouter(print, epoch, 'e (bare)', w, b, loss_bare, 0))\n",
    "\topt_bare.step()                               ; records.append(recouter(print, epoch, 'f (bare)', w, b, loss_bare, 0))\n",
    "\t\n",
    "\t# 模型实现 step\n",
    "\tprint(\"=== mod ===\")                ; records.append(recouter(print, epoch, 'a (mod)', model.w, model.b, loss_mod, 0))\n",
    "\tp_mod = model(X)                    ; records.append(recouter(print, epoch, 'b (mod)', model.w, model.b, loss_mod, 0))\n",
    "\tloss_mod = loss_fn(p_mod, y)        ; records.append(recouter(print, epoch, 'c (mod)', model.w, model.b, loss_mod, 0))\n",
    "\topt_mod.zero_grad()                 ; records.append(recouter(print, epoch, 'd (mod)', model.w, model.b, loss_mod, 0))\n",
    "\tloss_mod.backward()                 ; records.append(recouter(print, epoch, 'e (mod)', model.w, model.b, loss_mod, 0))\n",
    "\topt_mod.step()                      ; records.append(recouter(print, epoch, 'f (mod)', model.w, model.b, loss_mod, 0))\n",
    "\n",
    "import polars as pl\n",
    "records_df = pl.DataFrame(records)\n",
    "\n",
    "# 比较最终参数与损失\n",
    "print('final bias diff:', abs(b.item() - model.b.item()))\n",
    "print('final weight diff:', (w - model.w).abs().max().item())\n",
    "print('final loss diff:', abs(loss_bare.item() - loss_mod.item()))\n",
    "\n",
    "opt_bare, opt_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98be5c96-79fd-4aa8-8e9b-f3d526049085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (36, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;a (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;b (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;c (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;d (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;e (bare)&quot;</td><td>0.0</td><td>-86.795395</td><td>0.0</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;f (bare)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2</td><td>&quot;a (mod)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>2</td><td>&quot;b (mod)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>2</td><td>&quot;c (mod)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;d (mod)&quot;</td><td>1.718171</td><td>null</td><td>0.06766</td><td>null</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;e (mod)&quot;</td><td>1.718171</td><td>-83.284286</td><td>0.06766</td><td>-3.128763</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;f (mod)&quot;</td><td>2.551013</td><td>-83.284286</td><td>0.098948</td><td>-3.128763</td><td>1816.008301</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (36, 7)\n",
       "┌───────┬──────────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step     ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---      ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str      ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 0     ┆ a (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ b (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ c (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ d (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ e (bare) ┆ 0.0      ┆ -86.795395 ┆ 0.0      ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 0     ┆ f (bare) ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ …     ┆ …        ┆ …        ┆ …          ┆ …        ┆ …         ┆ …           │\n",
       "│ 2     ┆ a (mod)  ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 2     ┆ b (mod)  ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 2     ┆ c (mod)  ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1816.008301 │\n",
       "│ 2     ┆ d (mod)  ┆ 1.718171 ┆ null       ┆ 0.06766  ┆ null      ┆ 1816.008301 │\n",
       "│ 2     ┆ e (mod)  ┆ 1.718171 ┆ -83.284286 ┆ 0.06766  ┆ -3.128763 ┆ 1816.008301 │\n",
       "│ 2     ┆ f (mod)  ┆ 2.551013 ┆ -83.284286 ┆ 0.098948 ┆ -3.128763 ┆ 1816.008301 │\n",
       "└───────┴──────────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(12)\n",
    "records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8170360f-a8e7-4896-bafb-317d50e954f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;a (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;b (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;c (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;d (bare)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;e (bare)&quot;</td><td>0.0</td><td>-86.795395</td><td>0.0</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;f (bare)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;a (mod)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;b (mod)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>NaN</td></tr><tr><td>0</td><td>&quot;c (mod)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;d (mod)&quot;</td><td>0.0</td><td>null</td><td>0.0</td><td>null</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;e (mod)&quot;</td><td>0.0</td><td>-86.795395</td><td>0.0</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>0</td><td>&quot;f (mod)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 7)\n",
       "┌───────┬──────────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step     ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---      ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str      ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 0     ┆ a (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ b (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ c (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ d (bare) ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ e (bare) ┆ 0.0      ┆ -86.795395 ┆ 0.0      ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 0     ┆ f (bare) ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 0     ┆ a (mod)  ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ b (mod)  ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ NaN         │\n",
       "│ 0     ┆ c (mod)  ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ d (mod)  ┆ 0.0      ┆ null       ┆ 0.0      ┆ null      ┆ 1962.344482 │\n",
       "│ 0     ┆ e (mod)  ┆ 0.0      ┆ -86.795395 ┆ 0.0      ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 0     ┆ f (mod)  ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "└───────┴──────────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df.filter(pl.col(\"epoch\") == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2048f7c1-2fb8-4c09-b0b3-c03edce26af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>&quot;a (bare)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>1</td><td>&quot;b (bare)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>1</td><td>&quot;c (bare)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;d (bare)&quot;</td><td>0.867954</td><td>null</td><td>0.034696</td><td>null</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;e (bare)&quot;</td><td>0.867954</td><td>-85.02166</td><td>0.034696</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;f (bare)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;a (mod)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>1</td><td>&quot;b (mod)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1962.344482</td></tr><tr><td>1</td><td>&quot;c (mod)&quot;</td><td>0.867954</td><td>-86.795395</td><td>0.034696</td><td>-3.469604</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;d (mod)&quot;</td><td>0.867954</td><td>null</td><td>0.034696</td><td>null</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;e (mod)&quot;</td><td>0.867954</td><td>-85.02166</td><td>0.034696</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>1</td><td>&quot;f (mod)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 7)\n",
       "┌───────┬──────────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step     ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---      ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str      ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 1     ┆ a (bare) ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 1     ┆ b (bare) ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 1     ┆ c (bare) ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1887.662476 │\n",
       "│ 1     ┆ d (bare) ┆ 0.867954 ┆ null       ┆ 0.034696 ┆ null      ┆ 1887.662476 │\n",
       "│ 1     ┆ e (bare) ┆ 0.867954 ┆ -85.02166  ┆ 0.034696 ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 1     ┆ f (bare) ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 1     ┆ a (mod)  ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 1     ┆ b (mod)  ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1962.344482 │\n",
       "│ 1     ┆ c (mod)  ┆ 0.867954 ┆ -86.795395 ┆ 0.034696 ┆ -3.469604 ┆ 1887.662476 │\n",
       "│ 1     ┆ d (mod)  ┆ 0.867954 ┆ null       ┆ 0.034696 ┆ null      ┆ 1887.662476 │\n",
       "│ 1     ┆ e (mod)  ┆ 0.867954 ┆ -85.02166  ┆ 0.034696 ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 1     ┆ f (mod)  ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "└───────┴──────────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df.filter(pl.col(\"epoch\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb6aaa76-81c5-4e9f-84ea-a9b8d69ae46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>step</th><th>w</th><th>w.grad</th><th>b</th><th>b.grad</th><th>loss</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>&quot;a (bare)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>2</td><td>&quot;b (bare)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>2</td><td>&quot;c (bare)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;d (bare)&quot;</td><td>1.718171</td><td>null</td><td>0.06766</td><td>null</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;e (bare)&quot;</td><td>1.718171</td><td>-83.284286</td><td>0.06766</td><td>-3.128763</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;f (bare)&quot;</td><td>2.551013</td><td>-83.284286</td><td>0.098948</td><td>-3.128763</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;a (mod)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>2</td><td>&quot;b (mod)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1887.662476</td></tr><tr><td>2</td><td>&quot;c (mod)&quot;</td><td>1.718171</td><td>-85.02166</td><td>0.06766</td><td>-3.296391</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;d (mod)&quot;</td><td>1.718171</td><td>null</td><td>0.06766</td><td>null</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;e (mod)&quot;</td><td>1.718171</td><td>-83.284286</td><td>0.06766</td><td>-3.128763</td><td>1816.008301</td></tr><tr><td>2</td><td>&quot;f (mod)&quot;</td><td>2.551013</td><td>-83.284286</td><td>0.098948</td><td>-3.128763</td><td>1816.008301</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (12, 7)\n",
       "┌───────┬──────────┬──────────┬────────────┬──────────┬───────────┬─────────────┐\n",
       "│ epoch ┆ step     ┆ w        ┆ w.grad     ┆ b        ┆ b.grad    ┆ loss        │\n",
       "│ ---   ┆ ---      ┆ ---      ┆ ---        ┆ ---      ┆ ---       ┆ ---         │\n",
       "│ i64   ┆ str      ┆ f64      ┆ f64        ┆ f64      ┆ f64       ┆ f64         │\n",
       "╞═══════╪══════════╪══════════╪════════════╪══════════╪═══════════╪═════════════╡\n",
       "│ 2     ┆ a (bare) ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 2     ┆ b (bare) ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 2     ┆ c (bare) ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1816.008301 │\n",
       "│ 2     ┆ d (bare) ┆ 1.718171 ┆ null       ┆ 0.06766  ┆ null      ┆ 1816.008301 │\n",
       "│ 2     ┆ e (bare) ┆ 1.718171 ┆ -83.284286 ┆ 0.06766  ┆ -3.128763 ┆ 1816.008301 │\n",
       "│ 2     ┆ f (bare) ┆ 2.551013 ┆ -83.284286 ┆ 0.098948 ┆ -3.128763 ┆ 1816.008301 │\n",
       "│ 2     ┆ a (mod)  ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 2     ┆ b (mod)  ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1887.662476 │\n",
       "│ 2     ┆ c (mod)  ┆ 1.718171 ┆ -85.02166  ┆ 0.06766  ┆ -3.296391 ┆ 1816.008301 │\n",
       "│ 2     ┆ d (mod)  ┆ 1.718171 ┆ null       ┆ 0.06766  ┆ null      ┆ 1816.008301 │\n",
       "│ 2     ┆ e (mod)  ┆ 1.718171 ┆ -83.284286 ┆ 0.06766  ┆ -3.128763 ┆ 1816.008301 │\n",
       "│ 2     ┆ f (mod)  ┆ 2.551013 ┆ -83.284286 ┆ 0.098948 ┆ -3.128763 ┆ 1816.008301 │\n",
       "└───────┴──────────┴──────────┴────────────┴──────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_df.filter(pl.col(\"epoch\") == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc09746-bce1-453b-af06-1b6d2346c9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (user venv)",
   "language": "python",
   "name": "root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
